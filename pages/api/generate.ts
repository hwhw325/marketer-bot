import { NextApiRequest, NextApiResponse } from 'next'
import OpenAI from 'openai'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method !== 'POST') {
    return res.status(405).end()
  }

  const { topic, tone, mood, audience, purpose } = req.body

  if (!topic) {
    return res.status(400).json({ result: 'í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.' })
  }

  const prompt = `ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬ ì´ëª¨ì§€ 1ê°œê°€ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨ëœ ë§ˆì¼€íŒ… ë¬¸êµ¬ë¥¼ 3ê°œ ì‘ì„±í•´ì¤˜.
ê° ë¬¸ì¥ ì•ì—ëŠ” ìˆ«ì(1. 2. 3.)ë¥¼ ë¶™ì—¬ì¤˜. ë¬¸ì¥ì€ ê°„ê²°í•˜ê³  ê°•ë ¬í•˜ê²Œ ì¨ì¤˜.

- ì£¼ì œ: ${topic}
- ë§íˆ¬ ìŠ¤íƒ€ì¼: ${tone || 'ê¸°ë³¸'}
- ë¶„ìœ„ê¸°: ${mood || 'ê¸°ë³¸'}
- íƒ€ê¹ƒì¸µ: ${audience || 'ì¼ë°˜'}
- ëª©ì : ${purpose || 'ì¼ë°˜'}

í˜•ì‹ ì˜ˆì‹œ:
1. âœ¨ ë°ê³  ìƒê¸° ë„˜ì¹˜ëŠ” í”¼ë¶€ë¥¼ ìœ„í•œ ë¹„íƒ€ë¯¼ ì„¸ëŸ¼ì„ ë§Œë‚˜ë³´ì„¸ìš”!
2. ğŸŒŸ ë°”ìœ í•˜ë£¨ ì†ì—ì„œë„ ì´‰ì´‰í•¨ì„ ì§€ì¼œì£¼ëŠ” ìš°ë¦¬ì˜ ë³´ìŠµ í¬ë¦¼!
3. ğŸ’¡ ë‹¹ì‹ ì˜ í”¼ë¶€ì— ìì‹ ê°ì„ ë”í•˜ëŠ” ë§ˆë²•ê°™ì€ í•œ ë°©ìš¸!`

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.85,
    })

    const rawResult = completion.choices[0].message.content || ''

    // ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” 3ê°œ ë¬¸ì¥ ë¶„ë¦¬
    const resultLines = rawResult
      .split(/\d\.\s?/)
      .filter(Boolean)
      .map((line, idx) => `${idx + 1}. ${line.trim()}`)

    res.status(200).json({ result: resultLines.join('\n') })
  } catch (error) {
    console.error('OpenAI API ì˜¤ë¥˜:', error)
    res.status(500).json({ result: 'ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' })
  }
}
