// pages/api/gpt.ts
import { NextApiRequest, NextApiResponse } from 'next';
import OpenAI from 'openai';

// ğŸ” í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° (.env.localì— ìˆì–´ì•¼ í•¨!)
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'í—ˆìš©ë˜ì§€ ì•Šì€ ìš”ì²­ì…ë‹ˆë‹¤.' });
  }

  const { prompt } = req.body;

  // âœ… í”„ë¡ íŠ¸ì—ì„œ ì˜¨ prompt í™•ì¸
  console.log('ğŸ“¨ ë°›ì€ í”„ë¡¬í”„íŠ¸:', prompt);

  if (!prompt) {
    return res.status(400).json({ error: 'í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.' });
  }

  try {
    // ğŸ” GPT-3.5 Turbo ëª¨ë¸ì— ìš”ì²­ ë³´ë‚´ê¸°
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [{ role: 'user', content: prompt }],
      temperature: 0.7,
    });

    const result = completion.choices?.[0]?.message?.content?.trim() || '';

    // âœ… ì‹¤ì œ ìƒì„±ëœ ê²°ê³¼ ì¶œë ¥
    console.log('ğŸ¯ ìƒì„±ëœ ê²°ê³¼:', result);

    res.status(200).json({ result });
  } catch (error: any) {
    console.error('âŒ OpenAI API ì˜¤ë¥˜:', error.response?.data || error.message);
    res.status(500).json({ error: 'ë¬¸êµ¬ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”.' });
  }
}
